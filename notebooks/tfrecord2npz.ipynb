{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "npz_path = '../data1'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def decode_shoulder_img(image_data, image_hw=256):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.reshape(image, [image_hw, image_hw, 3])  # explicit size needed for TPU\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def decode_gripper_img(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.reshape(image, [64, 64, 3])  # explicit size needed for TPU\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "dimensions = {'Pybullet': {'obs': 18,\n",
    "                           'obs_extra_info': 18,\n",
    "                           'acts': 7,\n",
    "                           'achieved_goals': 11,\n",
    "                           'achieved_goals_extra_info': 11,\n",
    "                           'shoulder_img_hw': 200,\n",
    "                           'hz': 25}}\n",
    "\n",
    "def read_tfrecord(include_imgs=False, include_imgs2=False, include_gripper_imgs=False, sim='Pybullet'):\n",
    "    def read_tfrecord_helper(example):\n",
    "        LABELED_TFREC_FORMAT = {\n",
    "            'obs': tf.io.FixedLenFeature([], tf.string),  # tf.string means bytestring,\n",
    "            'acts': tf.io.FixedLenFeature([], tf.string),  # tf.string means bytestring,\n",
    "            'achieved_goals': tf.io.FixedLenFeature([], tf.string),  # tf.string means bytestring,\n",
    "            'sequence_index': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'sequence_id': tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "        if include_imgs:\n",
    "            LABELED_TFREC_FORMAT['img'] = tf.io.FixedLenFeature([], tf.string)  # tf.string means bytestring\n",
    "        if include_imgs2:\n",
    "            LABELED_TFREC_FORMAT['img2'] = tf.io.FixedLenFeature([], tf.string)  # tf.string means bytestring\n",
    "        if include_gripper_imgs:\n",
    "            LABELED_TFREC_FORMAT['gripper_img'] = tf.io.FixedLenFeature([], tf.string)  # tf.string means bytestring\n",
    "\n",
    "        data = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "\n",
    "        output = {}\n",
    "        if include_imgs:\n",
    "            output['obs'] = tf.ensure_shape(tf.io.parse_tensor(data['obs'], tf.float32),\n",
    "                                            (dimensions[sim]['obs_extra_info'],))\n",
    "            output['achieved_goals'] = tf.ensure_shape(tf.io.parse_tensor(data['achieved_goals'], tf.float32),\n",
    "                                                       (dimensions[sim]['achieved_goals_extra_info'],))\n",
    "        else:\n",
    "            output['obs'] = tf.ensure_shape(tf.io.parse_tensor(data['obs'], tf.float32), (dimensions[sim]['obs'],))\n",
    "            output['achieved_goals'] = tf.ensure_shape(tf.io.parse_tensor(data['achieved_goals'], tf.float32),\n",
    "                                                       (dimensions[sim]['achieved_goals'],))\n",
    "\n",
    "        output['acts'] = tf.ensure_shape(tf.io.parse_tensor(data['acts'], tf.float32), (dimensions[sim]['acts'],))\n",
    "        output['sequence_index'] = tf.cast(data['sequence_index'], tf.int32)\n",
    "        output['sequence_id'] = tf.cast(data['sequence_id'], tf.int32)  # this is meant to be 32 even though you serialize as 64\n",
    "        if include_imgs:\n",
    "            output['img'] = decode_shoulder_img(data['img'], dimensions[sim]['shoulder_img_hw'])\n",
    "        if include_imgs2:\n",
    "            output['img2'] = decode_shoulder_img(data['img2'], dimensions[sim]['shoulder_img_hw'])\n",
    "        if include_gripper_imgs:\n",
    "            output['gripper_img'] = decode_gripper_img(data['gripper_img'])\n",
    "\n",
    "        return output\n",
    "\n",
    "    return read_tfrecord_helper"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def extract_tfrecords(paths, include_imgs=False, include_imgs2=False, include_gripper_imgs=False, sim='Pybullet',\n",
    "                      ordered=True, num_workers=1):\n",
    "    # In our case, order does matter\n",
    "    tf_options = tf.data.Options()\n",
    "    tf_options.experimental_deterministic = ordered  # must be 1 to maintain order while streaming from GCS\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(paths, num_parallel_reads=1)\n",
    "    dataset = dataset.with_options(tf_options)\n",
    "    dataset = dataset.map(read_tfrecord(include_imgs, include_imgs2, include_gripper_imgs, sim),\n",
    "                          num_parallel_calls=num_workers)\n",
    "    return dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "path = '../data/UR5'\n",
    "files = glob.glob(os.path.join(path, 'tf_records','*.tfrecords'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path2 = '../data1/UR5'\n",
    "for i, file in enumerate(files):\n",
    "    dataset = extract_tfrecords(file, include_imgs=True)\n",
    "    path_traj = os.path.join(path2, str(i))\n",
    "    if not os.path.exists(path_traj):\n",
    "        os.mkdir(path_traj)\n",
    "    path_traj_img = os.path.join(path_traj, 'imgs')\n",
    "    if not os.path.exists(path_traj_img):\n",
    "        os.mkdir(path_traj_img)\n",
    "    for j, data in enumerate(dataset):\n",
    "        img_np = data['img'].numpy()\n",
    "        Image.fromarray(img_np).save(os.path.join(path_traj_img,'image' + str(j) + '.png'))\n",
    "        i+=1\n",
    "\n",
    "    obs = np.array([data['obs'].numpy() for data in dataset])\n",
    "    acts = np.array([data['acts'].numpy() for data in dataset])\n",
    "    achieved_goals = np.array([data['achieved_goals'].numpy() for data in dataset])\n",
    "    sequence_index = np.array([data['sequence_index'].numpy() for data in dataset])\n",
    "    sequence_id = np.array([data['sequence_id'].numpy() for data in dataset])\n",
    "    d = {'obs': obs, 'acts': acts, 'achieved_goals': achieved_goals, 'sequence_index': sequence_index, 'sequence_id': sequence_id}\n",
    "    np.save(os.path.join(path_traj, 'data.npy'), d)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "lfp_amd_gpu",
   "language": "python",
   "display_name": "lfp_amd_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}